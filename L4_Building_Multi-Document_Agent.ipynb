{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b523e0a",
   "metadata": {},
   "source": [
    "# Lesson 4: Building a Multi-Document Agent\n",
    "\n",
    "In this lesson, we extend lesson 3 by handling multiple documents and increasing degrees of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a323703",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9625ab2-71b6-4fd0-904e-42df80d3215f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3221a474-5817-4db2-af46-e029042a75a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adaa26",
   "metadata": {},
   "source": [
    "## 1. Setup an agent over 3 papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b71ff6",
   "metadata": {},
   "source": [
    "**Note**: The pdf files are included with this lesson. To access these papers, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed10a24b-d65c-4b98-a93a-94ccdb8900d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
    "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
    "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    \"metagpt.pdf\",\n",
    "    \"longlora.pdf\",\n",
    "    \"selfrag.pdf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d0e53",
   "metadata": {},
   "source": [
    "For each paper, create the vector tool and the summary tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8f3185-3221-4b00-bd38-41d36e4a3307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: metagpt.pdf\n",
      "Getting tools for paper: longlora.pdf\n",
      "Getting tools for paper: selfrag.pdf\n"
     ]
    }
   ],
   "source": [
    "from utils import get_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bfe17",
   "metadata": {},
   "source": [
    "<div><img src=\"images/lesson4-1.png\" style=\"width: 50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e541bdd-14e1-41b6-81b5-b1bfda078d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff58c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2c6a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a124a438-5609-402e-8642-69d1088cb9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798d5d4",
   "metadata": {},
   "source": [
    "<div><img src=\"images/lesson4-2.png\" style=\"width: 50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17409d4c-05a9-4bf4-b74f-75135fa3cb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the dataset used in the Metagpt paper\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"dataset\"}\n",
      "=== Function Output ===\n",
      "The dataset mentioned in the context includes HumanEval, MBPP, and SoftwareDev. HumanEval comprises 164 handwritten programming tasks, MBPP consists of 427 Python tasks, and SoftwareDev includes 70 diverse software development tasks covering various scopes like mini-games, image processing algorithms, data visualization, and more. Each task in the SoftwareDev dataset is associated with specific code statistics, documentation statistics, cost statistics, cost of revision, and code executability metrics.\n",
      "=== LLM Response ===\n",
      "The dataset used in the MetaGPT paper includes HumanEval, MBPP, and SoftwareDev. HumanEval consists of 164 handwritten programming tasks, MBPP contains 427 Python tasks, and SoftwareDev comprises 70 diverse software development tasks covering various scopes such as mini-games, image processing algorithms, data visualization, and more. Each task in the SoftwareDev dataset is associated with specific code statistics, documentation statistics, cost statistics, cost of revision, and code executability metrics.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Tell me about the dataset used in the Metagpt paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05a61c",
   "metadata": {},
   "source": [
    "Here we ask for a summary from 2 papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace340b1-761f-4058-be41-68cf131541e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Give me a summary of both Self-RAG and LongLoRA\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_selfrag with args: {\"input\": \"Self-RAG\"}\n",
      "=== Function Output ===\n",
      "Self-RAG is a framework that enhances the quality and factuality of a large language model through a combination of retrieval and self-reflection. It aims to improve the generation quality of the language model by training it to retrieve relevant information on-demand and to reflect on its own output using special tokens called reflection tokens. This framework allows the language model to adaptively retrieve passages, generate responses, and evaluate the relevance and quality of its own output, ultimately leading to improved performance on various tasks compared to existing models like ChatGPT and retrieval-augmented Llama2-chat.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_longlora with args: {\"input\": \"LongLoRA\"}\n",
      "=== Function Output ===\n",
      "LongLoRA is an efficient method for extending the context length of Large Language Models (LLMs) while maintaining strong empirical results on various tasks. It combines shifted sparse attention (S2-Attn) with LoRA to effectively and efficiently fine-tune models for longer context lengths. This approach allows for significant context extension without altering the original model architectures, demonstrating improved training speed and reduced memory cost compared to full fine-tuning methods.\n",
      "=== LLM Response ===\n",
      "Here are summaries of Self-RAG and LongLoRA:\n",
      "\n",
      "1. Self-RAG: Self-RAG is a framework that enhances the quality and factuality of a large language model through a combination of retrieval and self-reflection. It aims to improve the generation quality of the language model by training it to retrieve relevant information on-demand and to reflect on its own output using special tokens called reflection tokens. This framework allows the language model to adaptively retrieve passages, generate responses, and evaluate the relevance and quality of its own output, ultimately leading to improved performance on various tasks compared to existing models like ChatGPT and retrieval-augmented Llama2-chat.\n",
      "\n",
      "2. LongLoRA: LongLoRA is an efficient method for extending the context length of Large Language Models (LLMs) while maintaining strong empirical results on various tasks. It combines shifted sparse attention (S2-Attn) with LoRA to effectively and efficiently fine-tune models for longer context lengths. This approach allows for significant context extension without altering the original model architectures, demonstrating improved training speed and reduced memory cost compared to full fine-tuning methods.\n",
      "assistant: Here are summaries of Self-RAG and LongLoRA:\n",
      "\n",
      "1. Self-RAG: Self-RAG is a framework that enhances the quality and factuality of a large language model through a combination of retrieval and self-reflection. It aims to improve the generation quality of the language model by training it to retrieve relevant information on-demand and to reflect on its own output using special tokens called reflection tokens. This framework allows the language model to adaptively retrieve passages, generate responses, and evaluate the relevance and quality of its own output, ultimately leading to improved performance on various tasks compared to existing models like ChatGPT and retrieval-augmented Llama2-chat.\n",
      "\n",
      "2. LongLoRA: LongLoRA is an efficient method for extending the context length of Large Language Models (LLMs) while maintaining strong empirical results on various tasks. It combines shifted sparse attention (S2-Attn) with LoRA to effectively and efficiently fine-tune models for longer context lengths. This approach allows for significant context extension without altering the original model architectures, demonstrating improved training speed and reduced memory cost compared to full fine-tuning methods.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Give me a summary of both Self-RAG and LongLoRA\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eede70c",
   "metadata": {},
   "source": [
    "## 2. Setup an agent over 11 papers\n",
    "\n",
    "Now let's extend the example to 11 papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18771e69",
   "metadata": {},
   "source": [
    "### Download 11 ICLR papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d01d2c-547f-4054-b0fe-ed9b1a9cc3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
    "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
    "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
    "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
    "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
    "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
    "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
    "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
    "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
    "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
    "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    \"metagpt.pdf\",\n",
    "    \"longlora.pdf\",\n",
    "    \"loftq.pdf\",\n",
    "    \"swebench.pdf\",\n",
    "    \"selfrag.pdf\",\n",
    "    \"zipformer.pdf\",\n",
    "    \"values.pdf\",\n",
    "    \"finetune_fair_diffusion.pdf\",\n",
    "    \"knowledge_card.pdf\",\n",
    "    \"metra.pdf\",\n",
    "    \"vr_mcl.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77426cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download these papers, below is the needed code:\n",
    "\n",
    "\n",
    "    #for url, paper in zip(urls, papers):\n",
    "         #!wget \"{url}\" -O \"{paper}\"\n",
    "    \n",
    "    \n",
    "**Note**: The pdf files are included with this lesson. To access these papers, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea5ee34d-02ac-4537-ae20-7ef6c5767172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: metagpt.pdf\n",
      "Getting tools for paper: longlora.pdf\n",
      "Getting tools for paper: loftq.pdf\n",
      "Getting tools for paper: swebench.pdf\n",
      "Getting tools for paper: selfrag.pdf\n",
      "Getting tools for paper: zipformer.pdf\n",
      "Getting tools for paper: values.pdf\n",
      "Getting tools for paper: finetune_fair_diffusion.pdf\n",
      "Getting tools for paper: knowledge_card.pdf\n",
      "Getting tools for paper: metra.pdf\n",
      "Getting tools for paper: vr_mcl.pdf\n"
     ]
    }
   ],
   "source": [
    "from utils import get_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35d52c",
   "metadata": {},
   "source": [
    "### Extend the Agent with Tool Retrieval\n",
    "\n",
    "When list of documents get larger (10, 100 or more), in this case 11 documents, we will encounter several issues:\n",
    "\n",
    "- stuffing all tool selections may not fit into the llm prompt\n",
    "- costs and latency will increase\n",
    "- llm get confused and unable to pick the right tool when number of tools are too large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf5c3f",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "Instead on text, we perform RAG on the list of tools. Retrieve the small subset of relevant tools, and feed as input to the reasoning prompt, instead of all the tools.\n",
    "\n",
    "<div><img src=\"images/lesson4-3.png\" style=\"width: 50%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5486c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbc012",
   "metadata": {},
   "source": [
    "First, define and object index over the tools and perform RAG on the tools using object retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "671582f9-70d7-4a8f-b813-58b2a068ca72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define an \"object\" index and retriever over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3929882-e9dc-46ca-b495-53e3ed60340e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9cfecd-fe14-4da8-b9ba-b3d485d98a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = obj_retriever.retrieve(\n",
    "    \"Tell me about the eval dataset used in MetaGPT and SWE-Bench\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df47defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of MetaGPT. Do NOT use if you have specific questions over MetaGPT.', name='summary_tool_swebench', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd1c1d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of MetaGPT. Do NOT use if you have specific questions over MetaGPT.', name='summary_tool_metra', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c270ffbf-69c7-48ea-a028-9ba25221cde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of MetaGPT. Do NOT use if you have specific questions over MetaGPT.', name='summary_tool_values', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc0a0b6-9858-4348-9ae0-1cd4160f3fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given papers.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a250cf1a-e011-4994-bcca-4e0294f20864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation dataset used in MetaGPT and compare it against SWE-Bench\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metra with args: {\"input\": \"evaluation dataset used in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The evaluation dataset used in MetaGPT is not explicitly mentioned in the provided context information.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_swebench with args: {\"input\": \"evaluation dataset used in SWE-Bench\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15970313835327787 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 56708, Requested 3581. Please try again in 289ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38518828733557353 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 56671, Requested 3634. Please try again in 305ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2682222109943396 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 56519, Requested 3759. Please try again in 278ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.12302487860926359 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59771, Requested 3987. Please try again in 3.758s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6993495421095638 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59761, Requested 4010. Please try again in 3.771s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6481131894512959 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59307, Requested 4396. Please try again in 3.703s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.6521909915920814 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 56281, Requested 3759. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.0487465895439991 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59674, Requested 4010. Please try again in 3.684s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.431316264303683 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59571, Requested 4396. Please try again in 3.967s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "The evaluation dataset used in SWE-Bench consists of task instances collected from real GitHub issues and pull requests across popular Python repositories. It includes task instructions, issue text, retrieved files, an example patch file, and a prompt for generating the patch file. The dataset is constructed by scraping pull requests from the top Python libraries, validated through execution-based verification, and continuously updated with new task instances. The finalized task instances are validated through execution-based steps and saved in a .json file for download, along with corresponding ground truth test results. The dataset involves tasks related to software engineering problems from various repositories, including specific issues like handling QDP files and resolving cyclic dependencies.\n",
      "=== LLM Response ===\n",
      "The evaluation dataset used in MetaGPT is not explicitly mentioned in the provided context information. \n",
      "\n",
      "On the other hand, the evaluation dataset used in SWE-Bench consists of task instances collected from real GitHub issues and pull requests across popular Python repositories. It includes task instructions, issue text, retrieved files, an example patch file, and a prompt for generating the patch file. The dataset is constructed by scraping pull requests from the top Python libraries, validated through execution-based verification, and continuously updated with new task instances. The finalized task instances are validated through execution-based steps and saved in a .json file for download, along with corresponding ground truth test results. The dataset involves tasks related to software engineering problems from various repositories, including specific issues like handling QDP files and resolving cyclic dependencies.\n",
      "assistant: The evaluation dataset used in MetaGPT is not explicitly mentioned in the provided context information. \n",
      "\n",
      "On the other hand, the evaluation dataset used in SWE-Bench consists of task instances collected from real GitHub issues and pull requests across popular Python repositories. It includes task instructions, issue text, retrieved files, an example patch file, and a prompt for generating the patch file. The dataset is constructed by scraping pull requests from the top Python libraries, validated through execution-based verification, and continuously updated with new task instances. The finalized task instances are validated through execution-based steps and saved in a .json file for download, along with corresponding ground truth test results. The dataset involves tasks related to software engineering problems from various repositories, including specific issues like handling QDP files and resolving cyclic dependencies.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the evaluation dataset used \"\n",
    "    \"in MetaGPT and compare it against SWE-Bench\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8084c8cb-98ed-4835-aaa4-5b0c7254be6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Compare and contrast the LoRA papers (LongLoRA, LoftQ). Analyze the approach in each paper first. \n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_longlora with args: {\"input\": \"LongLoRA paper\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.357269422514362 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59587, Requested 3585. Please try again in 3.172s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.36399870525478184 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 59346, Requested 3820. Please try again in 3.166s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.0291031191695599 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 56348, Requested 3820. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "The LongLoRA paper introduces an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs) with limited computation cost. It utilizes shifted sparse attention (S2-Attn) during training to approximate long context effectively and efficiently. By combining this with a parameter-efficient fine-tuning regime, LongLoRA demonstrates strong empirical results on various tasks across different Llama2 models. The approach allows for extending the context of LLMs while retaining their original architectures and is compatible with existing techniques like Flash-Attention2. Additionally, LongLoRA improves training speed and memory efficiency compared to conventional methods, making it a valuable contribution to the field of large language models.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_loftq with args: {\"input\": \"LoftQ paper\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8639854401143886 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 57024, Requested 3087. Please try again in 111ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7122240588150683 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 56885, Requested 3226. Please try again in 111ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.7979608949358261 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-vqFYxgzzHIM2dUljWi76qehk on tokens per min (TPM): Limit 60000, Used 57367, Requested 3226. Please try again in 593ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "The LoftQ paper introduces a novel quantization framework designed for Large Language Models (LLMs) that integrates quantization and Low-Rank Adaptation (LoRA) fine-tuning. It aims to bridge the performance gap observed between full fine-tuning and quantization plus LoRA fine-tuning approaches when applied together on a pre-trained model. LoftQ simultaneously quantizes an LLM and finds a suitable low-rank initialization for LoRA fine-tuning, enhancing generalization in downstream tasks. The framework has been evaluated across various natural language tasks, demonstrating superior effectiveness, especially in challenging low-bit scenarios. Additionally, the paper discusses model compression ratios, memory footprints, quantization time, and GLUE dataset statistics, showcasing the comprehensive evaluation and performance of LoftQ.\n",
      "=== LLM Response ===\n",
      "The LongLoRA paper introduces an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs) with limited computation cost. It utilizes shifted sparse attention (S2-Attn) during training to approximate long context effectively and efficiently. By combining this with a parameter-efficient fine-tuning regime, LongLoRA demonstrates strong empirical results on various tasks across different Llama2 models. The approach allows for extending the context of LLMs while retaining their original architectures and is compatible with existing techniques like Flash-Attention2. Additionally, LongLoRA improves training speed and memory efficiency compared to conventional methods, making it a valuable contribution to the field of large language models.\n",
      "\n",
      "On the other hand, the LoftQ paper introduces a novel quantization framework designed for Large Language Models (LLMs) that integrates quantization and Low-Rank Adaptation (LoRA) fine-tuning. It aims to bridge the performance gap observed between full fine-tuning and quantization plus LoRA fine-tuning approaches when applied together on a pre-trained model. LoftQ simultaneously quantizes an LLM and finds a suitable low-rank initialization for LoRA fine-tuning, enhancing generalization in downstream tasks. The framework has been evaluated across various natural language tasks, demonstrating superior effectiveness, especially in challenging low-bit scenarios. Additionally, the paper discusses model compression ratios, memory footprints, quantization time, and GLUE dataset statistics, showcasing the comprehensive evaluation and performance of LoftQ.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Compare and contrast the LoRA papers (LongLoRA, LoftQ). \"\n",
    "    \"Analyze the approach in each paper first. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6fdd7",
   "metadata": {},
   "source": [
    "<div><img src=\"images/lesson4-4.png\" style=\"width: 50%\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
